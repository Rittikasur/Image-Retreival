# -*- coding: utf-8 -*-
"""Testing on raw data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KN9YWDkv5y-t_HcDO5ihpXS1rigT-oj2
"""

import os
import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2

from sklearn.neighbors import NearestNeighbors
from sklearn.manifold import TSNE

import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import *
from tensorflow.keras.applications import *
import tensorflow_hub as hub

import tensorflow_datasets as tfds
tfds.disable_progress_bar()

# Fix the random seeds
SEEDS=666

np.random.seed(SEEDS)
tf.random.set_seed(SEEDS)

from google.colab import drive
drive.mount('/content/drive')

IMAGE_SIZE = 160

# Image preprocessing utils
def preprocess_test(image):
    image = cv2.imread(os.path.join(image))
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])
    image = tf.cast(image, tf.float32) / 255.0
    image = tf.expand_dims(image, axis=0) # it expands the dimensions, as our BigT model will take an input of 4 dims
    return image

data_dir = "/content/drive/MyDrive/ORG_India/all_data"

import os
path =r"/content/drive/MyDrive/ORG_India/all_data"
list_of_files = []

for root, dirs, files in os.walk(path):
	for file in files:
		list_of_files.append(os.path.join(root,file))

model_url = "https://tfhub.dev/google/bit/m-r50x1/1"
module = hub.KerasLayer(model_url, trainable=False)

class MyBiTModel(tf.keras.Model):
  def __init__(self, module):
    super().__init__()
    self.dense1 = tf.keras.layers.Dense(128)
    self.normalize = Lambda(lambda a: tf.math.l2_normalize(a, axis=1))
    self.bit_model = module
  
  def call(self, images):
    bit_embedding = self.bit_model(images)
    dense1_representations = self.dense1(bit_embedding)
    return self.normalize(dense1_representations)

model = MyBiTModel(module=module)

model.build(input_shape=(None, IMAGE_SIZE, IMAGE_SIZE, 3))
model.load_weights("/content/drive/MyDrive/ORG_India/Research_weights/BiT_KNN/model_bigt.h5")

validation_features=[]
image = []
for i in list_of_files:
  images = preprocess_test(i)
  #images.shape
  result = model.predict(images)
  image.append(images)
  validation_features.append(result)

image = np.array(image)
image = image.reshape(6035,160, 160, 3)
#print(image.shape)

validation_features = np.array(validation_features)
validation_features = validation_features.reshape(6035,128)

#validation_features = model.predict(images)
#start = time.time()
neighbors = NearestNeighbors(n_neighbors=5,
    algorithm='brute',
    metric='euclidean').fit(validation_features)
#print('Time taken: {:.5f} secs'.format(time.time() - start))

import pickle
knnPickle = open('knn_org_data', 'wb') 
      
# source, destination 
pickle.dump(neighbors, knnPickle)  

# close the file
knnPickle.close()

def plot_images(images,distances):
    plt.figure(figsize=(20, 10))
    columns = 4
    for (i, image) in enumerate(images):
        ax = plt.subplot(len(images) / columns + 1, columns, i + 1)
        if i == 0:
            ax.set_title("Query Image\n" )
        else:
            ax.set_title("Similar Image # " + str(i) +
                         "\nDistance: " +
                         str(float("{0:.2f}".format(distances[i]))))
        plt.imshow(image)

for i in range(10):
    random_index = int(np.random.choice(image.shape[0], 1))
    distances, indices = neighbors.kneighbors(
        [validation_features[random_index]])
    
    # Don't take the first closest image as it will be the same image
    #print(random_index,len(images))
    #print(indices[0])
    similar_images = [image[random_index]] + [image[indices[0][i]] for i in range(1, 4)]
    
    similar_images = tf.squeeze(similar_images)
    plot_images(similar_images, distances[0])

